# Многомодельный чат для коллективной работы

Система для коллективной работы нескольких LLM AI моделей, которые совместно решают задачи путем обсуждения и передачи ответов друг другу.

## Концепция

Вместо использования одной AI модели, система объединяет три различные модели:

- **Gemini** - общие вопросы, креативный анализ, математика, перевод
- **DeepSeek** - Глубокий технический анализ, алгоритмы, системная архитектура
- **GigaChat** - Креативные задачи, генерация контента, синтез решений

Модели взаимодействуют между собой, обсуждают варианты решения и передают предложения друг другу для получения наилучшего результата.

## Как это работает

1. **Пользователь задает вопрос** через веб-интерфейс
2. **Старотовая модель** (по умолчанию Gemini) получает запрос от пользователя с контекстом о других доступных моделях
3. **Модель принимает решение:**

- REQUEST_TO_MODEL / Обратиться к другой модели для получения лучшего ответа
- USER_QUESTION / Задать пользователю уточняющий вопрос
- FINAL_ANSWER / Дать окончательный ответ

4. **Процесс продолжается** до получения окончательного ответа
5. **Пользователь видит** как весь процесс обсуждения, так и конечный результат

### Типы задач

### Технические задачи

- Решение системных проблем
- Оптимизация и улучшение качества кода
- Разработка алгоритмов и архитектуры

### Аналитические задачи

- Обработка и анализ данных
- Прогнозирование
- Бизнес-аналитика

### Креативные задачи

- Создание концепций и сценариев
- Генерация идей для контента
- Разработка брендинга и нейминг

### Образовательные задачи

- Объяснение сложных концепций
- Проверка знаний
- Пошаговые руководства

### Преимущества системы

### Качество решений

- **Специализация:** Задачи решают подходящие для нее модели
- **Самопроверка:** Модели могут выявлять ошибки друг друга
- **Глубина проработки:** Возможность анализировать сложные и комплексные задачи

### Прозрачность процесса

- Пользователь наблюдает весь процесс принятия решений
- Возможность проследить логику рассуждений

### Гибкость

- Модели адаптируются к типу задачи
- Можно переключать модели по необходимости
- Поддерживает как быстрые ответы, так и глубокую проработку вопроса

### Архитектура

### Backend (Python + FastAPI)

app/ # Основная логика приложения
├── core/ #Конфигурация проекта и глобальные зависимости
├── api/ # REST API эндпоинты
├── models/ # Модели данных
├── services/ # Бизнес-логика приложения
│ ├── chat_service.py # Бизнес-логика чата
│ ├── session_service.py # Бизнес-логика управления сессиями
│ └── ai_models/ # Инстансы AI моделей
└── utils/ # Воспомогательные функции

### Установка и запуск

### Backend

cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

### API документация

После запуска приложения документация доступна по адресу: http://localhost:8000/docs
